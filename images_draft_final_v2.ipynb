{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'field_crops.db'\n",
    "crop_table = 'midwest_key_field_crops_cleaned'\n",
    "area_table = 'midwest_area_planted_cleaned'\n",
    "conn = sqlite3.connect(db_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scale = alt.Scale(domain=['CORN', 'SOYBEANS', 'WHEAT'],\n",
    "                        range=['#FFB14E', '#FA8775', '#B5E384'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'static_final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Select \n",
    "    commodity_desc,\n",
    "    year, \n",
    "    sum(value) as total_prod\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year >= 1975\n",
    "group by \n",
    "    commodity_desc, year\n",
    "\"\"\"\n",
    "agg_prod_region_all_years = pd.read_sql(query, conn)\n",
    "\n",
    "chart = alt.Chart(agg_prod_region_all_years).mark_area().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('total_prod:Q', axis=alt.Axis(title='Total Production (in BUs)')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Commodity\"))\n",
    ").properties(\n",
    "    title=alt.TitleParams(\n",
    "        text='Total Crop Production Over Time',\n",
    "        subtitle='Corn, Soybeans, and Wheat (in BU)',\n",
    "        anchor='middle'\n",
    "    ),\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "file_name = '01_AGG_PRODUCTION_BY_CROP'\n",
    "chart.save(f'{output_path}{file_name}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Area Planted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Select \n",
    "    commodity_desc,\n",
    "    year, \n",
    "    sum(value) as total_area_planted,\n",
    "    count(*) as num_counties\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year >= 1975\n",
    "group by \n",
    "    commodity_desc, year\n",
    "\"\"\"\n",
    "agg_area_planted_region_all_years = pd.read_sql(query, conn)\n",
    "\n",
    "chart = alt.Chart(agg_area_planted_region_all_years).mark_area().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('total_area_planted:Q', axis=alt.Axis(title='Total Area Planted (in Acres)')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Commodity\"))   \n",
    "    ).properties(\n",
    "        title=alt.TitleParams(\n",
    "            text='Total Area Planted Over Time in Acres',\n",
    "            subtitle='Corn, Soybeans, and Wheat',\n",
    "            anchor='middle'\n",
    "        ),\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate productivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_yield_region_all_years = pd.merge(agg_area_planted_region_all_years, agg_prod_region_all_years, on=['commodity_desc', 'year'])\n",
    "agg_yield_region_all_years['yield'] = agg_yield_region_all_years['total_prod'] / agg_yield_region_all_years['total_area_planted']\n",
    "\n",
    "agg_yield_region_all_years\n",
    "\n",
    "chart = alt.Chart(agg_yield_region_all_years).mark_line().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('yield:Q', axis=alt.Axis(title='Yield')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Crop\"))   \n",
    "    ).properties(\n",
    "        title='Aggregate Yield Over Time',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated by State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Change Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS pres_prod,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_2015_2020 = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS past_prod,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_prod_1975_1980 = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS pres_area,\n",
    "    state_alpha\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_area_2015_2020 = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS past_area,\n",
    "    state_alpha\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_area_1975_1980 = pd.read_sql(query, conn)\n",
    "\n",
    "avg_yield_past = pd.merge(avg_area_1975_1980, avg_prod_1975_1980, on=[\"state_alpha\"])\n",
    "avg_yield_past[\"yield_past\"] = (avg_yield_past['past_prod'] / avg_yield_past['past_area']) \n",
    "\n",
    "avg_yield_present = pd.merge(avg_area_2015_2020, avg_prod_2015_2020, on=[\"state_alpha\"])\n",
    "avg_yield_present[\"yield_present\"] = (avg_yield_present['pres_prod'] / avg_yield_present['pres_area']) \n",
    "\n",
    "yield_change = pd.merge(avg_yield_past, avg_yield_present, on=[ \"state_alpha\"])\n",
    "\n",
    "yield_change[\"abs_change_yield\"] = (yield_change['yield_present'] -  yield_change['yield_past']) \n",
    "yield_change[\"perc_change_yield\"] = ((yield_change['yield_present'] -  yield_change['yield_past']) / yield_change['yield_past'])*100\n",
    "yield_change\n",
    "\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS Value_20,\n",
    "    commodity_desc,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha, commodity_desc\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_2015_2020 = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS Value_70,\n",
    "    commodity_desc,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_1975_1980 = pd.read_sql(query, conn)\n",
    "\n",
    "prod_change = pd.merge(avg_prod_2015_2020, avg_prod_1975_1980, on=[\"commodity_desc\", \"state_alpha\"])\n",
    "prod_change[\"abs_change_in_prod\"] = (prod_change['Value_20'] -  prod_change['Value_70']) \n",
    "\n",
    "# Calculate the total production change per state and sort by this total\n",
    "state_totals = prod_change.groupby('state_alpha')['abs_change_in_prod'].sum().sort_values(ascending=False)\n",
    "prod_change['state_alpha'] = pd.Categorical(prod_change['state_alpha'], categories=state_totals.index, ordered=True)\n",
    "\n",
    "# Create the bar chart with sorted states (highest total on the left)\n",
    "bar_chart = alt.Chart(prod_change).mark_bar().encode(\n",
    "    x=alt.X('state_alpha:O', title='State', sort=state_totals.index.tolist()),\n",
    "    y=alt.Y('abs_change_in_prod:Q', title='Change in Production (in BU)'),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Commodity\")), \n",
    "    xOffset='commodity_desc:N'\n",
    ")\n",
    "line_chart = alt.Chart(yield_change).mark_line(color='red').encode(\n",
    "    x=alt.X('state_alpha:O', title='State', sort=state_totals.index.tolist()),\n",
    "    y=alt.Y('abs_change_yield:Q', title='Change in Yield Over Period'),\n",
    ")\n",
    "combined_chart = alt.layer(bar_chart, line_chart).resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title=alt.TitleParams(\n",
    "        text='Absolute Change in Production Over Time in BU',\n",
    "        anchor='middle'\n",
    "    ),\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "combined_chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# County Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = data.us_10m.url  # URL for U.S. states\n",
    "counties = data.us_10m.url  # URL for U.S. counties\n",
    "states_gdf = gpd.read_file(states)\n",
    "counties_gdf = gpd.read_file(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_present,\n",
    "    commodity_desc,\n",
    "    state_alpha, \n",
    "    state_ansi|| county_ansi as id\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_present = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_past = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_present,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "avg_area_present = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "avg_area_past = pd.read_sql(query, conn)\n",
    "\n",
    "avg_yield_past = pd.merge(avg_prod_past, avg_area_past, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_past[\"yield_past\"] = (avg_yield_past['avg_prod_past'] / avg_yield_past['avg_area_past']) \n",
    "\n",
    "avg_yield_present = pd.merge(avg_prod_present, avg_area_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_present[\"yield_present\"] = (avg_yield_present['avg_prod_present'] / avg_yield_present['avg_area_present']) \n",
    "\n",
    "yield_change = pd.merge(avg_yield_past, avg_yield_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "\n",
    "yield_change[\"abs_change_yield\"] = (yield_change['yield_present'] -  yield_change['yield_past']) \n",
    "yield_change[\"perc_change_yield\"] = ((yield_change['yield_present'] -  yield_change['yield_past']) / yield_change['yield_past'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Select \n",
    "    distinct\n",
    "    state_ansi\n",
    "from {crop_table} \n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "check = pd.read_sql(query, conn)\n",
    "\n",
    "state_ansi_list = check.iloc[:,0].to_list()\n",
    "midwest_counties_gdf = counties_gdf[counties_gdf['id'].str[:2].isin(state_ansi_list)]\n",
    "midwest_counties_gdf = midwest_counties_gdf[\n",
    "    counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "    (counties_gdf['id'].str.len() == 5)  \n",
    "]\n",
    "\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, midwest_counties_gdf, on='id', how='left'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "\n",
    "crop_list = [ 'CORN', 'SOYBEANS', 'WHEAT']\n",
    "\n",
    "# Load U.S. states data\n",
    "states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "\n",
    "# Define state IDs for the Midwestern states\n",
    "midwestern_state_ids = [17, 18, 19, 20, 26, 27, 29, 31, 38, 39, 46, 55]\n",
    "\n",
    "# Filter the background chart for the selected states and add black borders\n",
    "state_map_background = alt.Chart(states).mark_geoshape(\n",
    "    fill=None,\n",
    "    stroke='black',  # Set border color to black\n",
    "    strokeWidth=1.5  # Adjust width as needed\n",
    ").transform_filter(\n",
    "    alt.FieldOneOfPredicate(field='id', oneOf=midwestern_state_ids)\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ").project('albersUsa')\n",
    "\n",
    "for crop in crop_list:\n",
    "    crop_df = merged[merged['commodity_desc']== crop]\n",
    "\n",
    "    # Define the background chart with a gray fill and black stroke for county borders\n",
    "    county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "        fill='lightgray',  # Background color\n",
    "        stroke='black',    # Outline color for counties\n",
    "        strokeWidth=0.5    # Thickness of county borders\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Define the filled map chart\n",
    "    county_map_filled = alt.Chart(crop_df).mark_geoshape(\n",
    "        stroke='black',   # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).encode(\n",
    "        color=alt.Color('abs_change_yield:Q',       \n",
    "                        scale=alt.Scale(\n",
    "                        scheme='redblue',        # Sequential color scale for yield change       # Adjust domain to match data range for more contrast\n",
    "        )),  # Sequential color scale for the 'value' column\n",
    "        tooltip=['id:N', 'abs_change_yield:Q']  # Tooltip with county ID and value\n",
    "    ).properties(\n",
    "        title=f'Map of Yield Change for {crop}',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Layer the filled map on top of the gray background\n",
    "    layered_map = county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "    # Display the chart\n",
    "    layered_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters\n",
    "noaa_midwest_codes = [\"11\", \"12\", \"13\", \"14\", \"20\", \"21\", \"23\", \"25\", \"32\", \"33\", \"39\", \"47\"]\n",
    "\n",
    "fips_mapping = {\n",
    "    \"11\": \"17\",  # Illinois\n",
    "    \"12\": \"18\",  # Indiana\n",
    "    \"13\": \"19\",  # Iowa\n",
    "    \"14\": \"20\",  # Kansas\n",
    "    \"20\": \"26\",  # Michigan\n",
    "    \"21\": \"27\",  # Minnesota\n",
    "    \"23\": \"29\",  # Missouri\n",
    "    \"25\": \"31\",  # Nebraska\n",
    "    \"32\": \"38\",  # North Dakota\n",
    "    \"33\": \"39\",  # Ohio\n",
    "    \"39\": \"46\",  # South Dakota\n",
    "    \"47\": \"55\"   # Wisconsin\n",
    "}\n",
    "\n",
    "final_df_cols = ['Year', 'County_Code', 'state_fips']\n",
    "\n",
    "def parse_climdiv_data(file_path, yearly_avg_column_name, midwest_codes=noaa_midwest_codes, final_df_cols=final_df_cols):\n",
    "    # Define the column widths based on the provided positions\n",
    "    column_specs = [\n",
    "        (0, 2),    # STATE-CODE (1-2)\n",
    "        (2, 5),    # DIVISION-NUMBER (3-5)\n",
    "        (5, 7),    # ELEMENT CODE (6-7)\n",
    "        (7, 11),   # YEAR (8-11)\n",
    "        (11, 18),  # JAN-VALUE (12-18)\n",
    "        (18, 25),  # FEB-VALUE (19-25)\n",
    "        (25, 32),  # MAR-VALUE (26-32)\n",
    "        (32, 39),  # APR-VALUE (33-39)\n",
    "        (39, 46),  # MAY-VALUE (40-46)\n",
    "        (46, 53),  # JUNE-VALUE (47-53)\n",
    "        (53, 60),  # JULY-VALUE (54-60)\n",
    "        (60, 67),  # AUG-VALUE (61-67)\n",
    "        (67, 74),  # SEPT-VALUE (68-74)\n",
    "        (74, 81),  # OCT-VALUE (75-81)\n",
    "        (81, 88),  # NOV-VALUE (82-88)\n",
    "        (88, 95),  # DEC-VALUE (89-95)\n",
    "    ]\n",
    "\n",
    "    # Column names\n",
    "    column_names = [\n",
    "        \"State_Code\", \"Division_Number\", \"Element_Code\", \"Year\",\n",
    "        \"Jan_Value\", \"Feb_Value\", \"Mar_Value\", \"Apr_Value\", \"May_Value\", \n",
    "        \"Jun_Value\", \"Jul_Value\", \"Aug_Value\", \"Sep_Value\", \"Oct_Value\", \n",
    "        \"Nov_Value\", \"Dec_Value\"\n",
    "    ]\n",
    "    \n",
    "    # Read the fixed-width file, treating State_Code and Division_Number as strings\n",
    "    df = pd.read_fwf(file_path, colspecs=column_specs, names=column_names, \n",
    "                     dtype={\"State_Code\": str, \"Division_Number\": str})\n",
    "\n",
    "    \n",
    "    # Create a new 'state_fips' column that maps the State_Code using the fips_mapping dictionary\n",
    "    df['state_fips'] = df['State_Code'].map(fips_mapping)  # All values are strings\n",
    "\n",
    "    # Create a new column that combines State_Code and Division_Number\n",
    "    df['County_Code'] = df['state_fips'] + df['Division_Number']\n",
    "\n",
    "    # Convert monthly values to numeric, replacing missing indicators\n",
    "    numeric_columns = column_names[4:]\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Handle missing values based on given missing indicators\n",
    "    df.replace({\n",
    "        \"Jan_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Feb_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Mar_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Apr_Value\": {-99.99: None, -9.99: None},\n",
    "        \"May_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Jun_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Jul_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Aug_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Sep_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Oct_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Nov_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Dec_Value\": {-99.99: None, -9.99: None}\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Calculate the yearly average, ignoring missing values\n",
    "    df[yearly_avg_column_name] = df[numeric_columns].mean(axis=1)\n",
    "\n",
    "    midwest_df = df[df['State_Code'].isin(midwest_codes)]\n",
    "\n",
    "    midwest_df_post1960 = midwest_df[midwest_df['Year'] > 1950]\n",
    "\n",
    "    output_columns = final_df_cols + [yearly_avg_column_name]\n",
    "    \n",
    "    return midwest_df_post1960[output_columns]\n",
    "\n",
    "precipitation_path = 'data/climate_data/climdiv-pcpncy-v1.0.0-20241021.txt'\n",
    "avg_temp_path = 'data/climate_data/climdiv-tmpccy-v1.0.0-20241021.txt'\n",
    "max_temp_path = 'data/climate_data/climdiv-tmaxcy-v1.0.0-20241021.txt'\n",
    "min_temp_path = 'data/climate_data/climdiv-tmincy-v1.0.0-20241021.txt'\n",
    "precip_df = parse_climdiv_data(precipitation_path, \"ann_avg_precip\")\n",
    "avg_temp_df = parse_climdiv_data(avg_temp_path, \"ann_avg_temp\")\n",
    "max_temp_df = parse_climdiv_data(max_temp_path, \"ann_max_temp\")\n",
    "min_temp_df = parse_climdiv_data(min_temp_path, \"ann_min_temp\")\n",
    "# Merge the DataFrames one by one\n",
    "merge_cols = ['Year', 'County_Code', 'state_fips']\n",
    "annual_climate_data_df = precip_df.merge(avg_temp_df, on=merge_cols).merge(max_temp_df, on=merge_cols).merge(min_temp_df, on=merge_cols)\n",
    "\n",
    "annual_climate_data_df = annual_climate_data_df.sort_values(by=['County_Code', 'Year'])\n",
    "\n",
    "# Apply rolling mean within each group\n",
    "rolling_avg_30yr_climate_data_df = (\n",
    "    annual_climate_data_df\n",
    "    .groupby('County_Code')[['Year', 'ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']]\n",
    "    .apply(lambda x: x.set_index('Year').rolling(window=30).mean())\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midwest_counties(db_name, table, counties_gdf):\n",
    "    # SQL query to get distinct state ANSI codes\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        DISTINCT state_ansi\n",
    "    FROM {table} \n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to the database and execute the query\n",
    "    with sqlite3.connect(db_name) as conn:\n",
    "        check = pd.read_sql(query, conn)\n",
    "\n",
    "    # Extract the list of state ANSI codes\n",
    "    state_ansi_list = check.iloc[:, 0].to_list()\n",
    "    \n",
    "    # Filter the counties GeoDataFrame to include only Midwest counties\n",
    "    midwest_counties_gdf = counties_gdf[\n",
    "        counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "        (counties_gdf['id'].str.len() == 5)\n",
    "    ]\n",
    "\n",
    "    return midwest_counties_gdf\n",
    "\n",
    "def create_climate_maps(merged_1980, midwest_counties_gdf, climate_metrics):\n",
    "    \n",
    "    # backgrounds\n",
    "    # Define the background chart with a gray fill and black stroke for county borders\n",
    "    county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "        fill='lightgray',  # Background color\n",
    "        stroke='black',    # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Load U.S. states data\n",
    "    states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "\n",
    "    # Define state IDs for the Midwestern states\n",
    "    midwestern_state_ids = [17, 18, 19, 20, 26, 27, 29, 31, 38, 39, 46, 55]\n",
    "\n",
    "    # Filter the background chart for the selected states and add black borders\n",
    "    state_map_background = alt.Chart(states).mark_geoshape(\n",
    "        fill=None,\n",
    "        stroke='black',  # Set border color to black\n",
    "        strokeWidth=1.5  # Adjust width as needed\n",
    "    ).transform_filter(\n",
    "        alt.FieldOneOfPredicate(field='id', oneOf=midwestern_state_ids)\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')\n",
    "    \n",
    "    \n",
    "    \n",
    "    for metric in climate_metrics:\n",
    "        columns = ['id', 'geometry']\n",
    "        metric_df = merged_1980[columns + [metric]]\n",
    "\n",
    "        # Define the filled map chart\n",
    "        county_map_filled = alt.Chart(metric_df).mark_geoshape(\n",
    "            stroke='black',   # Outline color for counties\n",
    "            strokeWidth=0.5   # Thickness of county borders\n",
    "        ).encode(color=alt.Color(f'{metric}:Q',       \n",
    "                    scale=alt.Scale(\n",
    "                    scheme='redblue',        # Sequential color scale for yield change       # Adjust domain to match data range for more contrast\n",
    "        )),  # Sequential color scale for the metric\n",
    "            tooltip=['id:N', f'{metric}:Q'] # Tooltip with county ID and metric value\n",
    "        ).properties(\n",
    "            title=f'Change in Average Annual {metric}, between 1980 and 2023',\n",
    "            width=800,\n",
    "            height=500\n",
    "        ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "        # Layer the filled map on top of the gray background\n",
    "        layered_map = county_map_background + county_map_filled + state_map_background\n",
    "        # Display the chart\n",
    "        layered_map.show()\n",
    "\n",
    "def calc_difference(metric, type):\n",
    "    # Assuming rolling_avg_30yr_climate_data_df is your DataFrame\n",
    "    # Step 1: Filter the DataFrame\n",
    "    filtered_df = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980, 2023])]\n",
    "\n",
    "    # Step 2: Pivot the DataFrame to make 'Year' columns\n",
    "    pivot_df = filtered_df.pivot(index='County_Code', columns='Year', values=metric)\n",
    "\n",
    "    # Step 3: Calculate the difference between 2023 and 1980\n",
    "    if type == \"abs_change\":\n",
    "        pivot_df[f'{metric}_{type}'] = pivot_df[2023] - pivot_df[1980]\n",
    "    if type == \"pct_change\":\n",
    "        pivot_df[f'{metric}_{type}'] = ((pivot_df[2023] - pivot_df[1980]) / pivot_df[1980])*100\n",
    "\n",
    "    # Reset index if needed\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    # Now pivot_df contains the difference for each County_Code\n",
    "    return pivot_df, f'{metric}_{type}'\n",
    "\n",
    "def gen_change_df(climate_metrics, type):\n",
    "    change_df_list = []\n",
    "    for metric in climate_metrics:\n",
    "        change_df, col_name = calc_difference(metric, type)\n",
    "        # Append the relevant columns to the list\n",
    "        change_df_list.append(change_df[['County_Code', col_name]])\n",
    "    \n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    merge_cols = [ 'County_Code']\n",
    "    change_climate_data_df = change_df_list[0].merge(change_df_list[1], on=merge_cols).merge(change_df_list[2], on=merge_cols).merge(change_df_list[3], on=merge_cols)\n",
    "    change_climate_data_df.reset_index(drop=True, inplace=True)\n",
    "    return change_climate_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midwest_counties_gdf = load_midwest_counties(db_name, area_table, counties_gdf)\n",
    "\n",
    "# Example usage\n",
    "climate_metrics = ['ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']\n",
    "abs_change_climate_data_df = gen_change_df(climate_metrics,  \"abs_change\")\n",
    "pct_change_climate_data_df = gen_change_df(climate_metrics,  \"pct_change\")\n",
    "\n",
    "abs_change_climate_data_df.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "# Merge the result DataFrame with the GeoDataFrame\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(abs_change_climate_data_df, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "print(len(change_climate_data_gdf))\n",
    "\n",
    "climate_metrics = ['ann_avg_precip_abs_change', 'ann_avg_temp_abs_change', 'ann_max_temp_abs_change', 'ann_min_temp_abs_change']\n",
    "create_climate_maps(change_climate_data_gdf, midwest_counties_gdf, climate_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "print(len(change_climate_data_gdf))\n",
    "\n",
    "climate_metrics = ['ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']\n",
    "create_climate_maps(change_climate_data_gdf, midwest_counties_gdf, climate_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1980 Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "print(len(change_climate_data_gdf))\n",
    "\n",
    "climate_metrics = ['ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']\n",
    "create_climate_maps(change_climate_data_gdf, midwest_counties_gdf, climate_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Relative to optimal temp and precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "climate_data_1980['1980_temp_deviation'] = climate_data_1980['ann_avg_temp'] - 50\n",
    "climate_data_1980['1980_precip_deviation'] = climate_data_1980['ann_avg_precip'] - 3\n",
    "climate_data_1980 = climate_data_1980.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "\n",
    "climate_data_2023['2023_temp_deviation'] = climate_data_2023['ann_avg_temp'] - 50\n",
    "climate_data_2023['2023_precip_deviation'] = climate_data_2023['ann_avg_precip'] - 3\n",
    "climate_data_2023 = climate_data_2023.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "\n",
    "climate_data_1980_2023 = pd.merge(climate_data_1980, climate_data_2023, on='id')\n",
    "climate_data_1980_2023['temp_change_anchored'] = climate_data_1980_2023['2023_temp_deviation'] - climate_data_1980_2023['1980_temp_deviation']\n",
    "\n",
    "climate_data_1980_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "climate_data_1980['1980_temp_deviation'] = abs(climate_data_1980['ann_avg_temp'] - 50)\n",
    "climate_data_1980['1980_precip_deviation'] = abs(climate_data_1980['ann_avg_precip'] - 3)\n",
    "climate_data_1980 = climate_data_1980.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "\n",
    "climate_data_2023['2023_temp_deviation'] = abs(climate_data_2023['ann_avg_temp'] - 50)\n",
    "climate_data_2023['2023_precip_deviation'] = abs(climate_data_2023['ann_avg_precip'] - 3)\n",
    "climate_data_2023 = climate_data_2023.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "\n",
    "climate_data_1980_2023 = pd.merge(climate_data_1980, climate_data_2023, on='id')\n",
    "climate_data_1980_2023['temp_change_anchored'] = climate_data_1980_2023['2023_temp_deviation'] - climate_data_1980_2023['1980_temp_deviation']\n",
    "\n",
    "climate_data_1980_2023\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "print(len(change_climate_data_gdf))\n",
    "\n",
    "climate_metrics = ['temp_change_anchored']\n",
    "create_climate_maps(change_climate_data_gdf, midwest_counties_gdf, climate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 1980 data\n",
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "# Calculate deviation from a target temperature and precipitation\n",
    "climate_data_1980['1980_temp_deviation'] = abs(climate_data_1980['ann_avg_temp'] - 50)\n",
    "climate_data_1980['1980_precip_deviation'] = abs(climate_data_1980['ann_avg_precip'] - 3)\n",
    "\n",
    "# Define a function to categorize temperatures by range distance\n",
    "def temp_distance_category(temp):\n",
    "    if 48 <= temp <= 52:\n",
    "        return \"Optimal Range (48 - 52)\"\n",
    "    elif 46 <= temp < 48:\n",
    "        return \"Between 0-2 degrees below range\"\n",
    "    elif 44 <= temp < 46:\n",
    "        return \"Between 2-4 degrees below range\"\n",
    "    elif 42 <= temp < 44:\n",
    "        return \"Between 4-6 degrees below range\"\n",
    "    elif 40 <= temp < 42:\n",
    "        return \"Between 6-8 degrees below range\"\n",
    "    elif temp < 40:\n",
    "        return \"More than 8 degrees below range\"\n",
    "    elif 52 < temp <= 54:\n",
    "        return \"Between 0-2 degrees above range\"\n",
    "    elif 54 < temp <= 56:\n",
    "        return \"Between 2-4 degrees above range\"\n",
    "    elif 56 < temp <= 58:\n",
    "        return \"Between 4-6 degrees above range\"\n",
    "    elif 58 < temp <= 60:\n",
    "        return \"Between 6-8 degrees above range\"\n",
    "    else:\n",
    "        return \"More than 8 degrees above range\"\n",
    "\n",
    "# Apply the function to create the new categorical variable\n",
    "climate_data_1980['temp_distance_category'] = climate_data_1980['ann_avg_temp'].apply(temp_distance_category)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "climate_data_1980 = climate_data_1980.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "climate_data_1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scheme = {\n",
    "    \"Between 0-2 degrees below range\": \"#ADD8E6\",  # Light Blue\n",
    "    \"Between 2-4 degrees below range\": \"#87CEEB\",  # Sky Blue\n",
    "    \"Between 4-6 degrees below range\": \"#4682B4\",  # Steel Blue\n",
    "    \"Between 6-8 degrees below range\": \"#5F9EA0\",  # Cadet Blue\n",
    "    \"More than 8 degrees below range\": \"#1E90FF\",  # Dodger Blue\n",
    "    \"Optimal Range (48 - 52)\": \"#3CB371\",  # Lime Green,\n",
    "    \"Between 0-2 degrees above range\": \"#FFD700\",  # Gold\n",
    "    \"Between 2-4 degrees above range\": \"#FFA500\",  # Orange\n",
    "    \"Between 4-6 degrees above range\": \"#FF8C00\",  # Dark Orange\n",
    "    \"Between 6-8 degrees above range\": \"#FF4500\",  # Orange Red\n",
    "    \"More than 8 degrees above range\": \"#FF0000\"   # Red\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "    fill='lightgray',  # Background color\n",
    "    stroke='black',    # Outline color for counties\n",
    "    strokeWidth=0.5   # Thickness of county borders\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ").project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "# Load U.S. states data\n",
    "states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "\n",
    "# Define state IDs for the Midwestern states\n",
    "midwestern_state_ids = [17, 18, 19, 20, 26, 27, 29, 31, 38, 39, 46, 55]\n",
    "\n",
    "# Filter the background chart for the selected states and add black borders\n",
    "state_map_background = alt.Chart(states).mark_geoshape(\n",
    "    fill=None,\n",
    "    stroke='black',  # Set border color to black\n",
    "    strokeWidth=1.5  # Adjust width as needed\n",
    ").transform_filter(\n",
    "    alt.FieldOneOfPredicate(field='id', oneOf=midwestern_state_ids)\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ").project('albersUsa')\n",
    "\n",
    "# Define the filled map chart using the categorical variable\n",
    "county_map_filled = alt.Chart(change_climate_data_gdf).mark_geoshape(\n",
    "        stroke='black',   # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).encode(color=alt.Color('temp_distance_category:N',\n",
    "                    scale=alt.Scale(\n",
    "                        domain=list(color_scheme.keys()),\n",
    "                        range=list(color_scheme.values())\n",
    "            )\n",
    "        )\n",
    "    ).properties(\n",
    "        title='Temperature Distance from 48-52 Range in 1980',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "# Layer the filled map on top of the gray background\n",
    "layered_map =  county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "# Display the chart\n",
    "layered_map.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 1980 data\n",
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "# Calculate deviation from a target temperature and precipitation\n",
    "climate_data_2023['1980_temp_deviation'] = abs(climate_data_2023['ann_avg_temp'] - 50)\n",
    "climate_data_2023['1980_precip_deviation'] = abs(climate_data_2023['ann_avg_precip'] - 3)\n",
    "\n",
    "# Define a function to categorize temperatures by range distance\n",
    "# Apply the function to create the new categorical variable\n",
    "climate_data_2023['temp_distance_category'] = climate_data_2023['ann_avg_temp'].apply(temp_distance_category)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "climate_data_2023 = climate_data_2023.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "    fill='lightgray',  # Background color\n",
    "    stroke='black',    # Outline color for counties\n",
    "    strokeWidth=0.5   # Thickness of county borders\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ").project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "# Load U.S. states data\n",
    "states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "\n",
    "# Define state IDs for the Midwestern states\n",
    "midwestern_state_ids = [17, 18, 19, 20, 26, 27, 29, 31, 38, 39, 46, 55]\n",
    "\n",
    "# Filter the background chart for the selected states and add black borders\n",
    "state_map_background = alt.Chart(states).mark_geoshape(\n",
    "    fill=None,\n",
    "    stroke='black',  # Set border color to black\n",
    "    strokeWidth=1.5  # Adjust width as needed\n",
    ").transform_filter(\n",
    "    alt.FieldOneOfPredicate(field='id', oneOf=midwestern_state_ids)\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ").project('albersUsa')\n",
    "\n",
    "# Define the filled map chart using the categorical variable\n",
    "county_map_filled = alt.Chart(change_climate_data_gdf).mark_geoshape(\n",
    "        stroke='black',   # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).encode(color=alt.Color('temp_distance_category:N',\n",
    "                    scale=alt.Scale(\n",
    "                        domain=list(color_scheme.keys()),\n",
    "                        range=list(color_scheme.values())\n",
    "            )\n",
    "        )\n",
    "    ).properties(\n",
    "        title='Temperature Distance from 48-52 Range in 2023',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "# Layer the filled map on top of the gray background\n",
    "layered_map =  county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "# Display the chart\n",
    "layered_map.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield x Climate Data Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "corn_merged = merged[merged['commodity_desc']=='CORN']\n",
    "heatmap_df = corn_merged[['ann_avg_temp', 'ann_avg_precip', 'yield_past']]\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp:Q', bin=alt.Bin(maxbins=12), title='Temperature'),\n",
    "        y=alt.Y('ann_avg_precip:Q', bin=alt.Bin(maxbins=12), title='Precipitation'),\n",
    "        color=alt.Color('mean(yield_past):Q', scale=alt.Scale(scheme='viridis'), title='Present Yield (2018-2023)')\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Yield (1980)',\n",
    "            subtitle='Crop Yield (BU/acre) by Climate  ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "heatmap.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "corn_merged = merged[merged['commodity_desc']=='CORN']\n",
    "heatmap_df = corn_merged[['ann_avg_temp', 'ann_avg_precip', 'yield_present']]\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp:Q', bin=alt.Bin(maxbins=12), title='Temperature'),\n",
    "        y=alt.Y('ann_avg_precip:Q', bin=alt.Bin(maxbins=12), title='Precipitation'),\n",
    "        color=alt.Color('mean(yield_present):Q', scale=alt.Scale(scheme='viridis'), title='Present Yield (2018-2023)')\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Yield Change (1975-2023)',\n",
    "            subtitle='Average change in Crop Yield (BU/acre) for Counties Grouped by Long/Lat ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "heatmap.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "change_climate_data_gdf\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "merged = merged[['commodity_desc','abs_change_yield', 'ann_avg_temp_x', 'ann_avg_temp_y', 'geometry']]\n",
    "\n",
    "corn_merged = merged[merged['commodity_desc']=='CORN']\n",
    "heatmap_df = corn_merged[['ann_avg_temp_x', 'ann_avg_temp_y', 'abs_change_yield']]\n",
    "\n",
    "# Filter\n",
    "heatmap_df = heatmap_df[(heatmap_df['ann_avg_temp_x'] >= 44) & (heatmap_df['ann_avg_temp_x'] <= 56)]\n",
    "heatmap_df = heatmap_df[(heatmap_df['ann_avg_temp_y'] >= 44) & (heatmap_df['ann_avg_temp_y'] <= 56)]\n",
    "\n",
    "\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp_x:Q', bin=alt.Bin(maxbins=30), title='Temperature 1980'),\n",
    "        y=alt.Y('ann_avg_temp_y:Q', bin=alt.Bin(maxbins=30), title='Temp 2023'),\n",
    "        color=alt.Color('mean(abs_change_yield):Q', scale=alt.Scale(scheme='viridis'), title='Present Yield (2018-2023)')\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Yield Change (1975-2023)',\n",
    "            subtitle='Average change in Crop Yield (BU/acre) for Counties Grouped by Long/Lat ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "heatmap.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ansi_list = check.iloc[:,0].to_list()\n",
    "midwest_counties_gdf = counties_gdf[counties_gdf['id'].str[:2].isin(state_ansi_list)]\n",
    "midwest_counties_gdf = midwest_counties_gdf[\n",
    "    counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "    (counties_gdf['id'].str.len() == 5)  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'field_crops.db'\n",
    "table_prod = 'midwest_key_field_crops_cleaned'\n",
    "table_area = 'midwest_area_planted_cleaned'\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_present,\n",
    "    commodity_desc,\n",
    "    state_alpha, \n",
    "    state_ansi|| county_ansi as id\n",
    "from {table_prod} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_present = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {table_prod} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_past = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_present,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {table_area} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_area_present = pd.read_sql(query, conn)\n",
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {table_area} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "avg_area_past = pd.read_sql(query, conn)\n",
    "\n",
    "avg_yield_past = pd.merge(avg_prod_past, avg_area_past, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_past[\"yield_past\"] = (avg_yield_past['avg_prod_past'] / avg_yield_past['avg_area_past']) \n",
    "\n",
    "avg_yield_present = pd.merge(avg_prod_present, avg_area_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_present[\"yield_present\"] = (avg_yield_present['avg_prod_present'] / avg_yield_present['avg_area_present']) \n",
    "\n",
    "yield_change = pd.merge(avg_yield_past, avg_yield_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "\n",
    "yield_change[\"abs_change_yield\"] = (yield_change['yield_present'] -  yield_change['yield_past']) \n",
    "yield_change[\"perc_change_yield\"] = ((yield_change['yield_present'] -  yield_change['yield_past']) / yield_change['yield_past'])*100\n",
    "yield_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    distinct\n",
    "    state_ansi\n",
    "from {crop_table} \n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "check = pd.read_sql(query, conn)\n",
    "\n",
    "state_ansi_list = check.iloc[:,0].to_list()\n",
    "midwest_counties_gdf = counties_gdf[counties_gdf['id'].str[:2].isin(state_ansi_list)]\n",
    "midwest_counties_gdf = midwest_counties_gdf[\n",
    "    counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "    (counties_gdf['id'].str.len() == 5)  \n",
    "]\n",
    "\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, midwest_counties_gdf, on='id', how='left'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "\n",
    "crop_list = [ 'CORN', 'SOYBEANS', 'WHEAT']\n",
    "\n",
    "for crop in crop_list:\n",
    "    crop_df = merged[merged['commodity_desc']== crop]\n",
    "\n",
    "    # Define the background chart with a gray fill and black stroke for county borders\n",
    "    county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "        fill='lightgray',  # Background color\n",
    "        stroke='black',    # Outline color for counties\n",
    "        strokeWidth=0.5    # Thickness of county borders\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Define the filled map chart\n",
    "    county_map_filled = alt.Chart(crop_df).mark_geoshape(\n",
    "        stroke='black',   # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).encode(\n",
    "        color=alt.Color('yield_present:Q', scale=alt.Scale(scheme='redblue')),  # Sequential color scale for the 'value' column\n",
    "        tooltip=['id:N', 'yield_present:Q']  # Tooltip with county ID and value\n",
    "    ).properties(\n",
    "        title=f'Map of Avg Yield for {crop}: Present (2018-2023)',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Layer the filled map on top of the gray background\n",
    "    layered_map = county_map_background + county_map_filled\n",
    "\n",
    "    # Display the chart\n",
    "    layered_map.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    distinct\n",
    "    state_ansi\n",
    "from {table} \n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "check = pd.read_sql(query, conn)\n",
    "\n",
    "state_ansi_list = check.iloc[:,0].to_list()\n",
    "midwest_counties_gdf = counties_gdf[counties_gdf['id'].str[:2].isin(state_ansi_list)]\n",
    "midwest_counties_gdf = midwest_counties_gdf[\n",
    "    counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "    (counties_gdf['id'].str.len() == 5)  \n",
    "]\n",
    "\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, midwest_counties_gdf, on='id', how='left'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "\n",
    "crop_list = [ 'CORN', 'SOYBEANS', 'WHEAT']\n",
    "\n",
    "for crop in crop_list:\n",
    "    crop_df = merged[merged['commodity_desc']== crop]\n",
    "\n",
    "    # Define the background chart with a gray fill and black stroke for county borders\n",
    "    county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "        fill='lightgray',  # Background color\n",
    "        stroke='black',    # Outline color for counties\n",
    "        strokeWidth=0.5    # Thickness of county borders\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Define the filled map chart\n",
    "    county_map_filled = alt.Chart(crop_df).mark_geoshape(\n",
    "        stroke='black',   # Outline color for counties\n",
    "        strokeWidth=0.5   # Thickness of county borders\n",
    "    ).encode(\n",
    "        color=alt.Color('abs_change_yield:Q',       \n",
    "                        scale=alt.Scale(\n",
    "                        scheme='redblue',        # Sequential color scale for yield change       # Adjust domain to match data range for more contrast\n",
    "        )),  # Sequential color scale for the 'value' column\n",
    "        tooltip=['id:N', 'abs_change_yield:Q']  # Tooltip with county ID and value\n",
    "    ).properties(\n",
    "        title=f'Map of Production for {crop}',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  # Use Albers USA projection\n",
    "\n",
    "    # Layer the filled map on top of the gray background\n",
    "    layered_map = county_map_background + county_map_filled\n",
    "\n",
    "    # Display the chart\n",
    "    layered_map.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_change\n",
    "corn_yield_change = yield_change[yield_change['commodity_desc'] == 'CORN']\n",
    "corn_yield_change.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'field_crops.db'\n",
    "table = 'midwest_key_field_crops_cleaned'\n",
    "version = 'pct'\n",
    "\n",
    "#counties = data.us_10m.url  # URL for U.S. counties\n",
    "\n",
    "midwest_counties_gdf = load_midwest_counties(db_name, table, counties_gdf)\n",
    "\n",
    "\n",
    "pct_change_climate_data_df.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "# Merge the result DataFrame with the GeoDataFrame\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(pct_change_climate_data_df, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "# Set the geometry for the GeoDataFrame\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "print(len(change_climate_data_gdf))\n",
    "\n",
    "climate_metrics = [f'ann_avg_precip_{version}_change', f'ann_avg_temp_{version}_change', f'ann_max_temp_{version}_change', f'ann_min_temp_{version}_change']\n",
    "create_climate_maps(change_climate_data_gdf, midwest_counties_gdf, climate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_change_climate_data_df.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "pct_change_climate_data_df.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "#pct_change_climate_data_df.reset_index(drop=True, inplace=True)\n",
    "# merge with county yield data\n",
    "merged_pct_change = pd.merge(yield_change, pct_change_climate_data_df, on='id', how=\"left\")\n",
    "merged_abs_change = pd.merge(yield_change, abs_change_climate_data_df, on='id', how=\"left\")\n",
    "merged_abs_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023 climate data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_averages_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_averages_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "merged_2023 = pd.merge(yield_change, climate_averages_2023, on='id', how=\"left\")\n",
    "merged_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_features = [ 'ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']\n",
    "# Create a scatter plot with facets for each commodity\n",
    "corn_merged_2023  = merged_2023[merged_2023['commodity_desc']=='CORN']\n",
    "for feature in climate_features:\n",
    "    scatter = alt.Chart(corn_merged_2023).mark_circle(size=60).encode(\n",
    "        x=alt.X(\n",
    "            f'{feature}:Q',\n",
    "                    scale=alt.Scale(domain=[merged_2023[f'{feature}'].min(), merged_2023[f'{feature}'].max()])  # Set x-axis to start at 30\n",
    "        ),\n",
    "        y='yield_present:Q'\n",
    "    ).properties(\n",
    "        title='Scatter Plot with Quadratic Best Fit Line'\n",
    "    )\n",
    "\n",
    "    line_of_best_fit = scatter.transform_regression(\n",
    "    f'{feature}', 'yield_present', method=\"poly\",\n",
    "    ).transform_calculate(\n",
    "        ann_avg_temp_squared=f'datum.{feature} * datum.{feature}'\n",
    "    ).mark_line(color='red')\n",
    "\n",
    "\n",
    "    # Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "    chart = scatter + line_of_best_fit\n",
    "\n",
    "\n",
    "\n",
    "    # Display the chart\n",
    "    chart.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(corn_merged_2023).mark_bar().encode(\n",
    "    x=alt.X('ann_avg_temp', bin=alt.Bin(maxbins=30)),\n",
    "    y=alt.Y('count():Q', title='Average Value'),\n",
    "    tooltip=['ann_avg_temp', 'mean(yield_present)']\n",
    ")\n",
    "\n",
    "hist = alt.Chart(corn_merged_2023).mark_bar().encode(\n",
    "    x=alt.X('ann_avg_temp', bin=alt.Bin(maxbins=30)),\n",
    "    y='count()'\n",
    ")\n",
    "\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(corn_merged_2023).mark_bar().encode(\n",
    "    x=alt.X('ann_avg_temp', bin=alt.Bin(maxbins=30)),\n",
    "    y=alt.Y('mean(yield_present):Q', title='Average Value'),\n",
    "    tooltip=['ann_avg_temp', 'mean(yield_present)']\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1980 Yiel Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "\n",
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged).mark_circle(size=60).encode(\n",
    "    x=alt.X(\n",
    "        'ann_avg_temp:Q',  # Quantitative x-axis\n",
    "        scale=alt.Scale(domain=[30, merged['ann_avg_temp'].max()])  # Set x-axis to start at 30\n",
    "    ),\n",
    "    y='yield_past:Q'\n",
    ").properties(\n",
    "    title='Scatter Plot with Quadratic Best Fit Line'\n",
    ")\n",
    "\n",
    "# Create a quadratic line of best fit by using linear regression on ann_avg_temp and ann_avg_temp_squared\n",
    "line_of_best_fit = scatter.transform_regression(\n",
    "    'ann_avg_temp', 'yield_past', method=\"poly\",\n",
    ").transform_calculate(\n",
    "    ann_avg_temp_squared='datum.ann_avg_temp * datum.ann_avg_temp'\n",
    ").mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged).mark_circle(size=60).encode(\n",
    "    x=alt.X(\n",
    "        'ann_avg_precip:Q',  # Quantitative x-axis\n",
    "        #scale=alt.Scale(domain=[30, merged['ann_avg_precip'].max()])  # Set x-axis to start at 30\n",
    "    ),\n",
    "    y='yield_past:Q'\n",
    ").properties(\n",
    "    title='Scatter Plot with Quadratic Best Fit Line'\n",
    ")\n",
    "\n",
    "# Create a quadratic line of best fit by using linear regression on ann_avg_temp and ann_avg_temp_squared\n",
    "line_of_best_fit = scatter.transform_regression(\n",
    "    'ann_avg_precip', 'yield_past', method=\"poly\",\n",
    ").transform_calculate(\n",
    "    ann_avg_temp_squared='datum.ann_avg_precip * datum.ann_avg_precip'\n",
    ").mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pct change in climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged_pct_change).mark_circle(size=60).encode(\n",
    "    x='ann_avg_temp_pct_change:Q',  # Quantitative x-axis\n",
    "    y='abs_change_yield:Q',  # Quantitative y-axis\n",
    "    tooltip=['ann_avg_temp_pct_change', 'abs_change_yield']  # Tooltip showing values on hover\n",
    ").properties(\n",
    "    title='Scatter Plot with Line of Best Fit'\n",
    ")\n",
    "\n",
    "# Create a line of best fit (linear regression) and facet by commodity_desc\n",
    "line_of_best_fit = scatter.transform_regression('ann_avg_temp_pct_change', 'abs_change_yield').mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged_pct_change).mark_circle(size=60).encode(\n",
    "    x='ann_avg_precip_pct_change:Q',  # Quantitative x-axis\n",
    "    y='abs_change_yield:Q',  # Quantitative y-axis\n",
    "    tooltip=['ann_avg_precip_pct_change', 'abs_change_yield']  # Tooltip showing values on hover\n",
    ").properties(\n",
    "    title='Scatter Plot with Line of Best Fit'\n",
    ")\n",
    "\n",
    "# Create a line of best fit (linear regression) and facet by commodity_desc\n",
    "line_of_best_fit = scatter.transform_regression('ann_avg_precip_pct_change', 'abs_change_yield').mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged_pct_change).mark_circle(size=60).encode(\n",
    "    x='ann_max_temp_pct_change:Q',  # Quantitative x-axis\n",
    "    y='abs_change_yield:Q',  # Quantitative y-axis\n",
    "    tooltip=['ann_max_temp_pct_change', 'abs_change_yield']  # Tooltip showing values on hover\n",
    ").properties(\n",
    "    title='Scatter Plot with Line of Best Fit'\n",
    ")\n",
    "\n",
    "# Create a line of best fit (linear regression) and facet by commodity_desc\n",
    "line_of_best_fit = scatter.transform_regression('ann_max_temp_pct_change', 'abs_change_yield').mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged_pct_change).mark_circle(size=60).encode(\n",
    "    x='ann_min_temp_pct_change:Q',  # Quantitative x-axis\n",
    "    y='abs_change_yield:Q',  # Quantitative y-axis\n",
    "    tooltip=['ann_min_temp_pct_change', 'abs_change_yield']  # Tooltip showing values on hover\n",
    ").properties(\n",
    "    title='Scatter Plot with Line of Best Fit'\n",
    ")\n",
    "\n",
    "# Create a line of best fit (linear regression) and facet by commodity_desc\n",
    "line_of_best_fit = scatter.transform_regression('ann_min_temp_pct_change', 'abs_change_yield').mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abs change in climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with facets for each commodity\n",
    "scatter = alt.Chart(merged_abs_change).mark_circle(size=60).encode(\n",
    "    x='ann_avg_temp_abs_change:Q',  # Quantitative x-axis\n",
    "    y='abs_change_yield:Q',  # Quantitative y-axis\n",
    "    tooltip=['ann_avg_temp_abs_change', 'abs_change_yield']  # Tooltip showing values on hover\n",
    ").properties(\n",
    "    title='Scatter Plot with Line of Best Fit'\n",
    ")\n",
    "\n",
    "# Create a line of best fit (linear regression) and facet by commodity_desc\n",
    "line_of_best_fit = scatter.transform_regression('ann_avg_temp_abs_change', 'abs_change_yield').mark_line(color='red')\n",
    "\n",
    "# Combine the scatter plot and line of best fit, and facet by commodity_desc\n",
    "chart = scatter + line_of_best_fit\n",
    "\n",
    "# Facet the chart by 'commodity_desc'\n",
    "faceted_chart = chart.facet(\n",
    "    facet='commodity_desc:N',  # Use nominal encoding for faceting\n",
    "    columns=3  # Number of columns for the facets\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "faceted_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat map by climate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merged_abs_change[['commodity_desc','abs_change_yield', 'ann_avg_temp_abs_change', 'ann_avg_precip_abs_change']]\n",
    "\n",
    "merged_abs_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "heatmap_df = merged_abs_change[['commodity_desc','abs_change_yield', 'ann_avg_temp_abs_change', 'ann_avg_precip_abs_change']]\n",
    "\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp_abs_change:Q', bin=alt.Bin(maxbins=15), title='Absolute Change in Average Temperature'),\n",
    "        y=alt.Y('ann_avg_precip_abs_change:Q', bin=alt.Bin(maxbins=15), title='Absolute Change in Average Precipitation'),\n",
    "        color=alt.Color('mean(abs_change_yield):Q', scale=alt.Scale(scheme='viridis'), title='Absolute Change in Yield'),\n",
    "        tooltip=['ann_avg_temp_abs_change:Q', 'latitude:Q', 'mean(abs_change_yield):Q']\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Yield Change (1975-2023)',\n",
    "            subtitle='Average change in Crop Yield (BU/acre) for Counties Grouped by change in climate features ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )\n",
    "    .facet(\n",
    "        facet=alt.Facet('commodity_desc:N', title='Commodity Type'),\n",
    "        columns=3  # Adjust the number of columns as needed\n",
    "    )\n",
    "    .resolve_scale(\n",
    "        color='independent'  # Allows each facet to have its own color scale\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "heatmap.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "heatmap_df = merged_2023\n",
    "\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp:Q', bin=alt.Bin(maxbins=15), title='Absolute Change in Average Temperature'),\n",
    "        y=alt.Y('ann_avg_precip:Q', bin=alt.Bin(maxbins=15), title='Absolute Change in Average Precipitation'),\n",
    "        color=alt.Color('mean(abs_change_yield):Q', scale=alt.Scale(scheme='viridis'), title='Absolute Change in Yield'),\n",
    "        tooltip=['ann_avg_temp:Q', 'ann_avg_precip:Q', 'mean(abs_change_yield):Q']\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Yield Change (1975-2023)',\n",
    "            subtitle='Average change in Crop Yield (BU/acre) for Counties Grouped by change in climate features ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )\n",
    "    .facet(\n",
    "        facet=alt.Facet('commodity_desc:N', title='Commodity Type'),\n",
    "        columns=3  # Adjust the number of columns as needed\n",
    "    )\n",
    "    .resolve_scale(\n",
    "        color='independent'  # Allows each facet to have its own color scale\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "heatmap.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag-data-viz-5d2VArwu-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
