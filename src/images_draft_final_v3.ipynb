{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "from vega_datasets import data\n",
    "\n",
    "# set global vars\n",
    "db_name = '../data/field_crops.db'\n",
    "crop_table = 'midwest_key_field_crops_cleaned'\n",
    "area_table = 'midwest_area_planted_cleaned'\n",
    "output_path = '../static_final/'\n",
    "\n",
    "# db connection\n",
    "conn = sqlite3.connect(db_name) \n",
    "\n",
    "# color theme\n",
    "color_scale = alt.Scale(domain=['CORN', 'SOYBEANS', 'WHEAT'],\n",
    "                        range=['#FFB14E', '#FA8775', '#B5E384'])\n",
    "\n",
    "# create geopandas dfs\n",
    "url = data.us_10m.url\n",
    "states_gdf = gpd.read_file(url, layer='states')\n",
    "counties_gdf = gpd.read_file(url, layer='counties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull total crop production by year\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    commodity_desc,\n",
    "    year, \n",
    "    sum(value) as total_prod\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year >= 1975\n",
    "group by \n",
    "    commodity_desc, year\n",
    "\"\"\"\n",
    "agg_prod_region_all_years = pd.read_sql(query, conn)\n",
    "\n",
    "# make stacked area by commodity type\n",
    "chart = alt.Chart(agg_prod_region_all_years).mark_area().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('total_prod:Q', axis=alt.Axis(title='Crop Production in Bushels (bsh)')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Crop\"))\n",
    ").properties(\n",
    "    title=alt.TitleParams(\n",
    "        text='Annual Crop Production in the Midwest',\n",
    "        subtitle='Corn, Soybeans, and Wheat in bushels (bsh)',\n",
    "        anchor='middle'\n",
    "    ),\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# save chart\n",
    "file_name = '01_AGG_PRODUCTION_BY_CROP'\n",
    "chart.save(f'{output_path}{file_name}.png')\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Area Planted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull total area planted by year\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    commodity_desc,\n",
    "    year, \n",
    "    sum(value) as total_area_planted,\n",
    "    count(*) as num_counties\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year >= 1975\n",
    "group by \n",
    "    commodity_desc, year\n",
    "\"\"\"\n",
    "agg_area_planted_region_all_years = pd.read_sql(query, conn)\n",
    "\n",
    "# make stacked area\n",
    "chart = alt.Chart(agg_area_planted_region_all_years).mark_area().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('total_area_planted:Q', axis=alt.Axis(title='Total Area Planted (in Acres)')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Crop\"))   \n",
    "    ).properties(\n",
    "        title=alt.TitleParams(\n",
    "            text='Area Planted in Acres',\n",
    "            subtitle='Corn, Soybeans, and Wheat',\n",
    "            anchor='middle'\n",
    "        ),\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "# save chart\n",
    "file_name = '02_AGG_AREA_PLANTED_BY_CROP'\n",
    "chart.save(f'{output_path}{file_name}.png')\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge production and area planted data\n",
    "agg_yield_region_all_years = pd.merge(agg_area_planted_region_all_years, agg_prod_region_all_years, on=['commodity_desc', 'year'])\n",
    "agg_yield_region_all_years['yield'] = agg_yield_region_all_years['total_prod'] / agg_yield_region_all_years['total_area_planted']\n",
    "\n",
    "# line chart by commodity over time\n",
    "chart = alt.Chart(agg_yield_region_all_years).mark_line().encode(\n",
    "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
    "    y=alt.Y('yield:Q', axis=alt.Axis(title='Yield (bsh per acre)')),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Crop\"))   \n",
    "    ).properties(\n",
    "        title='Annnual Yield by Crop',\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "# save\n",
    "file_name = '03_AGG_YIELD_BY_CROP'\n",
    "chart.save(f'{output_path}{file_name}.png')\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Change Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in avg production and area planted from beginning and end of period by state across all crop types\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS pres_prod,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_2015_2020 = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS past_prod,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_prod_1975_1980 = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS pres_area,\n",
    "    state_alpha\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_area_2015_2020 = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS past_area,\n",
    "    state_alpha\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha\n",
    "\"\"\"\n",
    "avg_area_1975_1980 = pd.read_sql(query, conn)\n",
    "\n",
    "# calculate past yield by state\n",
    "avg_yield_past = pd.merge(avg_area_1975_1980, avg_prod_1975_1980, on=[\"state_alpha\"])\n",
    "avg_yield_past[\"yield_past\"] = (avg_yield_past['past_prod'] / avg_yield_past['past_area']) \n",
    "\n",
    "# calculate present yield by state\n",
    "avg_yield_present = pd.merge(avg_area_2015_2020, avg_prod_2015_2020, on=[\"state_alpha\"])\n",
    "avg_yield_present[\"yield_present\"] = (avg_yield_present['pres_prod'] / avg_yield_present['pres_area']) \n",
    "\n",
    "# merge and calculate change in yield\n",
    "yield_change = pd.merge(avg_yield_past, avg_yield_present, on=[ \"state_alpha\"])\n",
    "yield_change[\"abs_change_yield\"] = (yield_change['yield_present'] -  yield_change['yield_past']) \n",
    "yield_change[\"perc_change_yield\"] = ((yield_change['yield_present'] -  yield_change['yield_past']) / yield_change['yield_past'])*100\n",
    "\n",
    "# pull in production by crop type\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS Value_20,\n",
    "    commodity_desc,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_alpha, commodity_desc\n",
    "\"\"\"\n",
    "conn = sqlite3.connect(db_name) \n",
    "avg_prod_2015_2020 = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS Value_70,\n",
    "    commodity_desc,\n",
    "    state_alpha\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_alpha, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_1975_1980 = pd.read_sql(query, conn)\n",
    "\n",
    "# calculate change in production across time period\n",
    "prod_change = pd.merge(avg_prod_2015_2020, avg_prod_1975_1980, on=[\"commodity_desc\", \"state_alpha\"])\n",
    "prod_change[\"abs_change_in_prod\"] = (prod_change['Value_20'] -  prod_change['Value_70']) \n",
    "\n",
    "# sort states by increase in production amount \n",
    "state_totals = prod_change.groupby('state_alpha')['abs_change_in_prod'].sum().sort_values(ascending=False)\n",
    "prod_change['state_alpha'] = pd.Categorical(prod_change['state_alpha'], categories=state_totals.index, ordered=True)\n",
    "\n",
    "# make bar chart for production change by state and commodity type\n",
    "bar_chart = alt.Chart(prod_change).mark_bar().encode(\n",
    "    x=alt.X('state_alpha:O', title='State', sort=state_totals.index.tolist()),\n",
    "    y=alt.Y('abs_change_in_prod:Q', title='Change in Production (bsh)'),\n",
    "    color=alt.Color('commodity_desc:N', scale=color_scale, legend=alt.Legend(title=\"Crop\")), \n",
    "    xOffset='commodity_desc:N'\n",
    ")\n",
    "\n",
    "# make line chart for yield change\n",
    "line_chart = alt.Chart(yield_change).mark_line(color='red').encode(\n",
    "    x=alt.X('state_alpha:O', title='State', sort=state_totals.index.tolist()),\n",
    "    y=alt.Y('abs_change_yield:Q', title='Change in Yield (bsh / acre)'),\n",
    ")\n",
    "\n",
    "# combine\n",
    "combined_chart = alt.layer(bar_chart, line_chart).resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title=alt.TitleParams(\n",
    "        text='Change in Production and Yield by State',\n",
    "        subtitle='Between 1975 and 2023',\n",
    "        anchor='middle'\n",
    "    ),\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# save\n",
    "file_name = '04_STATE_PRODUCTION_AND_YIELD_CHANGE_BY_CROP'\n",
    "combined_chart.save(f'{output_path}{file_name}.png')\n",
    "combined_chart.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# County Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midwest_counties(db_name, table, counties_gdf):\n",
    "\n",
    "    query = f\"\"\"\n",
    "    Select \n",
    "        distinct\n",
    "        state_ansi\n",
    "    from {table} \n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_name) \n",
    "    check = pd.read_sql(query, conn)\n",
    "    \n",
    "    state_ansi_list = check.iloc[:,0].to_list()\n",
    "    midwest_counties_gdf = counties_gdf[counties_gdf['id'].str[:2].isin(state_ansi_list)]\n",
    "    midwest_counties_gdf = midwest_counties_gdf[\n",
    "        counties_gdf['id'].str[:2].isin(state_ansi_list) & \n",
    "        (counties_gdf['id'].str.len() == 5)  \n",
    "    ]\n",
    "\n",
    "    return midwest_counties_gdf\n",
    "\n",
    "def make_background_maps(midwest_counties_gdf, states_gdf):\n",
    "    county_map_background = alt.Chart(midwest_counties_gdf).mark_geoshape(\n",
    "        fill='lightgray', \n",
    "        stroke='black',    \n",
    "        strokeWidth=0.5   \n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa') \n",
    "\n",
    "    \n",
    "    midwestern_state_ids = [17, 18, 19, 20, 26, 27, 29, 31, 38, 39, 46, 55]\n",
    "    \n",
    "    state_map_background = alt.Chart(states_gdf).mark_geoshape(\n",
    "        fill=None,\n",
    "        stroke='black',  \n",
    "        strokeWidth=1.5 \n",
    "    ).transform_filter(\n",
    "        alt.FieldOneOfPredicate(field='id', oneOf=midwestern_state_ids)\n",
    "    ).properties(\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')\n",
    "    \n",
    "    return county_map_background, state_map_background\n",
    "\n",
    "def create_climate_maps(gpd, metric_col, metric_full_name):\n",
    "\n",
    "    columns = ['id', 'geometry']\n",
    "    metric_df = gpd[columns + [metric_col]]\n",
    "\n",
    "    county_map_filled = alt.Chart(metric_df).mark_geoshape(\n",
    "        stroke='black',   \n",
    "        strokeWidth=0.5   \n",
    "    ).encode(\n",
    "        color=alt.Color(\n",
    "            f'{metric_col}:Q',\n",
    "            scale=alt.Scale(\n",
    "                       scheme='redyellowgreen', \n",
    "                        domainMid=0,\n",
    "                        domain=[metric_df[f'{metric_col}'].min(), metric_df[f'{metric_col}'].max()]\n",
    "            ),\n",
    "            title=f'{metric_full_name}'\n",
    "        ),\n",
    "        tooltip=['id:N', f'{metric_col}:Q']\n",
    "    ).properties(\n",
    "        title=f'Change in Average Annual {metric_full_name}, between 1980 and 2023',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')\n",
    "\n",
    "    return county_map_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in production and area data by county for begin and end of period\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_present,\n",
    "    commodity_desc,\n",
    "    state_alpha, \n",
    "    state_ansi|| county_ansi as id\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_present = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_prod_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {crop_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi, commodity_desc\n",
    "\"\"\"\n",
    "avg_prod_past = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_present,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 2018 and 2023\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "avg_area_present = pd.read_sql(query, conn)\n",
    "query = f\"\"\"\n",
    "Select \n",
    "    avg(value) AS avg_area_past,\n",
    "    commodity_desc,\n",
    "    state_alpha,\n",
    "    state_ansi|| county_ansi as id\n",
    "from {area_table} \n",
    "where short_desc != 'CORN, SILAGE - PRODUCTION, MEASURED IN TONS'\n",
    "and asd_code != 99\n",
    "and county_ansi != \"\"\n",
    "and year between 1975 and 1980\n",
    "group by state_ansi|| county_ansi , commodity_desc\n",
    "\"\"\"\n",
    "avg_area_past = pd.read_sql(query, conn)\n",
    "\n",
    "# calc yield \n",
    "avg_yield_past = pd.merge(avg_prod_past, avg_area_past, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_past[\"yield_past\"] = (avg_yield_past['avg_prod_past'] / avg_yield_past['avg_area_past']) \n",
    "avg_yield_present = pd.merge(avg_prod_present, avg_area_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "avg_yield_present[\"yield_present\"] = (avg_yield_present['avg_prod_present'] / avg_yield_present['avg_area_present']) \n",
    "\n",
    "# calc change in yield\n",
    "yield_change = pd.merge(avg_yield_past, avg_yield_present, on=[\"commodity_desc\", \"id\", \"state_alpha\"])\n",
    "yield_change[\"abs_change_yield\"] = (yield_change['yield_present'] -  yield_change['yield_past']) \n",
    "yield_change[\"perc_change_yield\"] = ((yield_change['yield_present'] -  yield_change['yield_past']) / yield_change['yield_past'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make geopandas df with yield info\n",
    "midwest_counties_gdf = load_midwest_counties(db_name, crop_table, counties_gdf)\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, midwest_counties_gdf, on='id', how='left'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "# make background maps for layering\n",
    "county_map_background, state_map_background = make_background_maps(midwest_counties_gdf, states_gdf)\n",
    "\n",
    "# make corn yield change map\n",
    "corn_df = merged[merged['commodity_desc']== 'CORN']\n",
    "county_map_filled = create_climate_maps(corn_df, 'abs_change_yield', 'Change in Yield')\n",
    "\n",
    "# combine filled map with layers\n",
    "layered_map = county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "layered_map.show()\n",
    "file_name = '05_YIELD_CHANGE_MAP'\n",
    "layered_map.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping and filtering codes\n",
    "noaa_midwest_codes = [\"11\", \"12\", \"13\", \"14\", \"20\", \"21\", \"23\", \"25\", \"32\", \"33\", \"39\", \"47\"]\n",
    "fips_mapping = {\n",
    "    \"11\": \"17\",  # Illinois\n",
    "    \"12\": \"18\",  # Indiana\n",
    "    \"13\": \"19\",  # Iowa\n",
    "    \"14\": \"20\",  # Kansas\n",
    "    \"20\": \"26\",  # Michigan\n",
    "    \"21\": \"27\",  # Minnesota\n",
    "    \"23\": \"29\",  # Missouri\n",
    "    \"25\": \"31\",  # Nebraska\n",
    "    \"32\": \"38\",  # North Dakota\n",
    "    \"33\": \"39\",  # Ohio\n",
    "    \"39\": \"46\",  # South Dakota\n",
    "    \"47\": \"55\"   # Wisconsin\n",
    "}\n",
    "final_df_cols = ['Year', 'County_Code', 'state_fips']\n",
    "\n",
    "# function to parse raw input data\n",
    "def parse_climdiv_data(file_path, yearly_avg_column_name, midwest_codes=noaa_midwest_codes, final_df_cols=final_df_cols):\n",
    "    column_specs = [\n",
    "        (0, 2),    # STATE-CODE (1-2)\n",
    "        (2, 5),    # DIVISION-NUMBER (3-5)\n",
    "        (5, 7),    # ELEMENT CODE (6-7)\n",
    "        (7, 11),   # YEAR (8-11)\n",
    "        (11, 18),  # JAN-VALUE (12-18)\n",
    "        (18, 25),  # FEB-VALUE (19-25)\n",
    "        (25, 32),  # MAR-VALUE (26-32)\n",
    "        (32, 39),  # APR-VALUE (33-39)\n",
    "        (39, 46),  # MAY-VALUE (40-46)\n",
    "        (46, 53),  # JUNE-VALUE (47-53)\n",
    "        (53, 60),  # JULY-VALUE (54-60)\n",
    "        (60, 67),  # AUG-VALUE (61-67)\n",
    "        (67, 74),  # SEPT-VALUE (68-74)\n",
    "        (74, 81),  # OCT-VALUE (75-81)\n",
    "        (81, 88),  # NOV-VALUE (82-88)\n",
    "        (88, 95),  # DEC-VALUE (89-95)\n",
    "    ]\n",
    "\n",
    "    column_names = [\n",
    "        \"State_Code\", \"Division_Number\", \"Element_Code\", \"Year\",\n",
    "        \"Jan_Value\", \"Feb_Value\", \"Mar_Value\", \"Apr_Value\", \"May_Value\", \n",
    "        \"Jun_Value\", \"Jul_Value\", \"Aug_Value\", \"Sep_Value\", \"Oct_Value\", \n",
    "        \"Nov_Value\", \"Dec_Value\"\n",
    "    ]\n",
    "    \n",
    "    df = pd.read_fwf(file_path, colspecs=column_specs, names=column_names, \n",
    "                     dtype={\"State_Code\": str, \"Division_Number\": str})\n",
    "\n",
    "    df['state_fips'] = df['State_Code'].map(fips_mapping)\n",
    "    df['County_Code'] = df['state_fips'] + df['Division_Number']\n",
    "    numeric_columns = column_names[4:]\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # handle missing values\n",
    "    df.replace({\n",
    "        \"Jan_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Feb_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Mar_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Apr_Value\": {-99.99: None, -9.99: None},\n",
    "        \"May_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Jun_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Jul_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Aug_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Sep_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Oct_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Nov_Value\": {-99.99: None, -9.99: None},\n",
    "        \"Dec_Value\": {-99.99: None, -9.99: None}\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "    df[yearly_avg_column_name] = df[numeric_columns].mean(axis=1)\n",
    "\n",
    "    midwest_df = df[df['State_Code'].isin(midwest_codes)]\n",
    "\n",
    "    midwest_df_post1950 = midwest_df[midwest_df['Year'] > 1950]\n",
    "\n",
    "    output_columns = final_df_cols + [yearly_avg_column_name]\n",
    "    \n",
    "    return midwest_df_post1950[output_columns]\n",
    "\n",
    "precipitation_path = '../data/climate_data/climdiv-pcpncy-v1.0.0-20241021.txt'\n",
    "avg_temp_path = '../data/climate_data/climdiv-tmpccy-v1.0.0-20241021.txt'\n",
    "max_temp_path = '../data/climate_data/climdiv-tmaxcy-v1.0.0-20241021.txt'\n",
    "min_temp_path = '../data/climate_data/climdiv-tmincy-v1.0.0-20241021.txt'\n",
    "precip_df = parse_climdiv_data(precipitation_path, \"ann_avg_precip\")\n",
    "avg_temp_df = parse_climdiv_data(avg_temp_path, \"ann_avg_temp\")\n",
    "max_temp_df = parse_climdiv_data(max_temp_path, \"ann_max_temp\")\n",
    "min_temp_df = parse_climdiv_data(min_temp_path, \"ann_min_temp\")\n",
    "\n",
    "merge_cols = ['Year', 'County_Code', 'state_fips']\n",
    "annual_climate_data_df = precip_df.merge(avg_temp_df, on=merge_cols).merge(max_temp_df, on=merge_cols).merge(min_temp_df, on=merge_cols)\n",
    "annual_climate_data_df = annual_climate_data_df.sort_values(by=['County_Code', 'Year'])\n",
    "\n",
    "rolling_avg_30yr_climate_data_df = (\n",
    "    annual_climate_data_df\n",
    "    .groupby('County_Code')[['Year', 'ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']]\n",
    "    .apply(lambda x: x.set_index('Year').rolling(window=30).mean())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_difference(metric, type):\n",
    "\n",
    "    filtered_df = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980, 2023])]\n",
    "\n",
    "    pivot_df = filtered_df.pivot(index='County_Code', columns='Year', values=metric)\n",
    "\n",
    "    if type == \"abs_change\":\n",
    "        pivot_df[f'{metric}_{type}'] = pivot_df[2023] - pivot_df[1980]\n",
    "    if type == \"pct_change\":\n",
    "        pivot_df[f'{metric}_{type}'] = ((pivot_df[2023] - pivot_df[1980]) / pivot_df[1980])*100\n",
    "\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    return pivot_df, f'{metric}_{type}'\n",
    "\n",
    "def gen_change_df(climate_metrics, type):\n",
    "    change_df_list = []\n",
    "    for metric in climate_metrics:\n",
    "        change_df, col_name = calc_difference(metric, type)\n",
    "        # Append the relevant columns to the list\n",
    "        change_df_list.append(change_df[['County_Code', col_name]])\n",
    "    \n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    merge_cols = [ 'County_Code']\n",
    "    change_climate_data_df = change_df_list[0].merge(change_df_list[1], on=merge_cols).merge(change_df_list[2], on=merge_cols).merge(change_df_list[3], on=merge_cols)\n",
    "    change_climate_data_df.reset_index(drop=True, inplace=True)\n",
    "    return change_climate_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Change Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make change in climate geopandas df\n",
    "midwest_counties_gdf = load_midwest_counties(db_name, area_table, counties_gdf)\n",
    "climate_metrics = ['ann_avg_precip', 'ann_avg_temp', 'ann_max_temp', 'ann_min_temp']\n",
    "abs_change_climate_data_df = gen_change_df(climate_metrics,  \"abs_change\")\n",
    "abs_change_climate_data_df.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(abs_change_climate_data_df, midwest_counties_gdf, on='id', how='left'))\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "# gen background maps and chloropleth by precipitation change\n",
    "county_map_background, state_map_background = make_background_maps(midwest_counties_gdf, states_gdf)\n",
    "county_map_filled = create_climate_maps(change_climate_data_gdf, 'ann_avg_precip_abs_change', 'Change in inches')\n",
    "county_map_filled = county_map_filled.properties(title='Change in Annual Precipitation between 1980 and 2023')\n",
    "\n",
    "# Layer the filled map on top of the gray background\n",
    "layered_map = county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "# save\n",
    "layered_map.show()\n",
    "file_name = '05_PRECIP_CHANGE_MAP'\n",
    "layered_map.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Change Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generte change in ann temp map and layer with background maps\n",
    "county_map_filled = create_climate_maps(change_climate_data_gdf, 'ann_avg_temp_abs_change', 'Change in deg. F')\n",
    "county_map_filled = county_map_filled.properties(title='Change in Annual Average Temperature between 1980 and 2023')\n",
    "layered_map = county_map_background + county_map_filled + state_map_background\n",
    "\n",
    "# save\n",
    "layered_map.show()\n",
    "file_name = '06_TEMP_CHANGE_MAP'\n",
    "layered_map.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Climate Scatters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1980 = pd.merge(yield_change, climate_data_1980, on='id', how=\"left\")\n",
    "\n",
    "charts = []\n",
    "\n",
    "climate_features = [ 'ann_avg_precip', 'ann_avg_temp']\n",
    "x_axes = ['Average Annual Precipitation', 'Average Annual Temperature']\n",
    "# Create a scatter plot with facets for each commodity\n",
    "\n",
    "corn_merged_1980  = merged_1980[merged_1980['commodity_desc']=='CORN']\n",
    "for i, feature in enumerate(climate_features):\n",
    "    scatter = alt.Chart(corn_merged_1980).mark_circle(size=60).encode(\n",
    "        x=alt.X(\n",
    "            f'{feature}:Q',\n",
    "            scale=alt.Scale(domain=[merged_1980[f'{feature}'].min(), merged_1980[f'{feature}'].max()]),\n",
    "            title=x_axes[i]\n",
    "        ),\n",
    "        y=alt.Y('yield_past:Q', title='' if i == 1 else 'Yield (1980)')\n",
    "    )\n",
    "\n",
    "    line_of_best_fit = scatter.transform_regression(\n",
    "        f'{feature}', 'yield_past', method=\"poly\",\n",
    "    ).transform_calculate(\n",
    "        ann_avg_temp_squared=f'datum.{feature} * datum.{feature}'\n",
    "    ).mark_line(color='red')\n",
    "\n",
    "    chart = scatter + line_of_best_fit\n",
    "    charts.append(chart)\n",
    "\n",
    "# stitch the charts together horizontally\n",
    "final_chart = alt.hconcat(*charts).properties(\n",
    "    title=alt.TitleParams(\n",
    "        '1980: Yield x Climate Features',\n",
    "        anchor='middle',\n",
    "        fontSize=16\n",
    "    )\n",
    ")\n",
    "\n",
    "# save\n",
    "final_chart.show()\n",
    "file_name = '07_SCATTER_1980'\n",
    "final_chart.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2023 = pd.merge(yield_change, climate_data_2023, on='id', how=\"left\")\n",
    "\n",
    "climate_features = ['ann_avg_precip', 'ann_avg_temp']\n",
    "x_axes = ['Average Annual Precipitation', 'Average Annual Temperature']\n",
    "corn_merged_2023 = merged_2023[merged_2023['commodity_desc'] == 'CORN']\n",
    "\n",
    "charts = []\n",
    "\n",
    "for i, feature in enumerate(climate_features):\n",
    "    scatter = alt.Chart(corn_merged_2023).mark_circle(size=60).encode(\n",
    "        x=alt.X(\n",
    "            f'{feature}:Q',\n",
    "            scale=alt.Scale(domain=[merged_2023[f'{feature}'].min(), merged_2023[f'{feature}'].max()]),\n",
    "            title=x_axes[i]\n",
    "        ),\n",
    "        y=alt.Y('yield_present:Q', title='' if i == 1 else 'Yield (2023)')\n",
    "    )\n",
    "\n",
    "    line_of_best_fit = scatter.transform_regression(\n",
    "        f'{feature}', 'yield_present', method=\"poly\",\n",
    "    ).transform_calculate(\n",
    "        ann_avg_temp_squared=f'datum.{feature} * datum.{feature}'\n",
    "    ).mark_line(color='red')\n",
    "\n",
    "    chart = scatter + line_of_best_fit\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart = alt.hconcat(*charts).properties(\n",
    "    title=alt.TitleParams(\n",
    "        '2023: Yield x Climate Features',\n",
    "        anchor='middle',\n",
    "        fontSize=16\n",
    "    )\n",
    ")\n",
    "\n",
    "final_chart.show()\n",
    "file_name = '08_SCATTER_2023'\n",
    "final_chart.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "corn_merged = merged[merged['commodity_desc']=='CORN']\n",
    "corn_merged = corn_merged[(corn_merged['ann_avg_temp']>=36) & (corn_merged['ann_avg_temp']<=58)]\n",
    "heatmap_df = corn_merged[['ann_avg_temp', 'ann_avg_precip', 'yield_past']]\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp:Q', bin=alt.Bin(maxbins=12), title='Temperature (in deg. F)'),\n",
    "        y=alt.Y('ann_avg_precip:Q', bin=alt.Bin(maxbins=12), title='Precipitation (in inches)'),\n",
    "        color=alt.Color('mean(yield_past):Q', scale=alt.Scale(range = ['yellow', 'green'], domain=[20, 80] ), title='Avg Yield')\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Average Corn Yield (1975-1980)',\n",
    "            subtitle='Corn Yield (bsh/acre) for Counties Grouped by Climate Averages in 1980',\n",
    "\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )    \n",
    ")\n",
    "\n",
    "heatmap.display()\n",
    "file_name = '09_HEATMAP_1980'\n",
    "heatmap.save(f'{output_path}{file_name}.png')\n",
    "\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "\n",
    "merged = gpd.GeoDataFrame(pd.merge(yield_change, change_climate_data_gdf, on='id', how='inner'))\n",
    "merged.set_geometry('geometry', inplace=True)\n",
    "\n",
    "corn_merged = merged[merged['commodity_desc']=='CORN']\n",
    "corn_merged = corn_merged[(corn_merged['ann_avg_temp']>=36) & (corn_merged['ann_avg_temp']<=58)]\n",
    "heatmap_df = corn_merged[['ann_avg_temp', 'ann_avg_precip', 'yield_present']]\n",
    "heatmap = (\n",
    "    alt.Chart(heatmap_df)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X('ann_avg_temp:Q', bin=alt.Bin(maxbins=12), title='Temperature (in deg. F)'),\n",
    "        y=alt.Y('ann_avg_precip:Q', bin=alt.Bin(maxbins=12), title='Precipitation (in inches)'),\n",
    "        color=alt.Color('mean(yield_present):Q', scale=alt.Scale(range = ['yellow', 'green'], domain=[50, 150] ), title='Avg Yield')\n",
    "    )\n",
    "    .properties(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        title=alt.TitleParams(\n",
    "            text='Heat Map of Average Corn Yield (2018-2023)',\n",
    "            subtitle='Corn Yield (bsh/acre) for Counties Grouped by Climate Averages in 2023 ',\n",
    "            anchor='middle'\n",
    "    ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "heatmap.display()\n",
    "file_name = '10_HEATMAP_2023'\n",
    "heatmap.save(f'{output_path}{file_name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Map Relative to Optimal Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "climate_data_1980 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([1980])]\n",
    "climate_data_1980.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "\n",
    "def temp_distance_category(temp):\n",
    "    if 48 <= temp <= 52:\n",
    "        return \"Optimal Range (48 - 52)\"\n",
    "    elif 44 <= temp < 48:\n",
    "        return \"0-4 degrees below range\"\n",
    "    elif 40 <= temp < 44:\n",
    "        return \"4-8 degrees below range\"\n",
    "    elif temp < 40:\n",
    "        return \"More than 8 degrees below range\"\n",
    "    elif 52 < temp <= 56:\n",
    "        return \"0-4 degrees above range\"\n",
    "    elif 56 < temp <= 60:\n",
    "        return \"4-8 degrees above range\"\n",
    "    else:\n",
    "        return \"More than 8 degrees above range\"\n",
    "\n",
    "climate_data_1980['temp_distance_category'] = climate_data_1980['ann_avg_temp'].apply(temp_distance_category)\n",
    "climate_data_1980 = climate_data_1980.drop(['ann_max_temp', 'ann_min_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scheme = {\n",
    "    \"More than 8 degrees below range\": \"#00008B\",  # Dark Blue\n",
    "    \"4-8 degrees below range\": \"#4682B4\",  # Steel Blue\n",
    "    \"0-4 degrees below range\": \"#87CEEB\",  # Sky Blue\n",
    "    \"Optimal Range (48 - 52)\": \"#3CB371\",  # Lime Green\n",
    "    \"0-4 degrees above range\": \"#FFD700\",  # Gold\n",
    "    \"4-8 degrees above range\": \"#FFA500\",  # Orange\n",
    "    \"More than 8 degrees above range\": \"#FF0000\"   # Red\n",
    "}\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_1980, midwest_counties_gdf, on='id', how='left'))\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "county_map_background, state_map_background = make_background_maps(midwest_counties_gdf, states_gdf)\n",
    "  \n",
    "county_map_filled = alt.Chart(change_climate_data_gdf).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.5   \n",
    "    ).encode(color=alt.Color('temp_distance_category:N',\n",
    "                    scale=alt.Scale(\n",
    "                        domain=list(color_scheme.keys()),\n",
    "                        range=list(color_scheme.values())\n",
    "            ),\n",
    "            legend=alt.Legend(title=\"Temperature Range\") \n",
    "        )\n",
    "    ).properties(\n",
    "        title='Average Temperature Categories Relative to Optimal Temperature Range in 1980',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')\n",
    "\n",
    "layered_map =  county_map_background + county_map_filled + state_map_background\n",
    "layered_map.show()\n",
    "\n",
    "file_name = '11_TEMP_CAT_MAP_1980'\n",
    "layered_map.save(f'{output_path}{file_name}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "climate_data_2023 = rolling_avg_30yr_climate_data_df[rolling_avg_30yr_climate_data_df['Year'].isin([2023])]\n",
    "climate_data_2023.rename(columns={'County_Code': 'id'}, inplace=True)\n",
    "climate_data_2023['temp_distance_category'] = climate_data_2023['ann_avg_temp'].apply(temp_distance_category)\n",
    "climate_data_2023 = climate_data_2023.drop(['ann_max_temp', 'ann_min_temp'], axis=1)\n",
    "\n",
    "change_climate_data_gdf = gpd.GeoDataFrame(pd.merge(climate_data_2023, midwest_counties_gdf, on='id', how='left'))\n",
    "change_climate_data_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "county_map_background, state_map_background = make_background_maps(midwest_counties_gdf, states_gdf)\n",
    "\n",
    "county_map_filled = alt.Chart(change_climate_data_gdf).mark_geoshape(\n",
    "        stroke='black', \n",
    "        strokeWidth=0.5   \n",
    "    ).encode(color=alt.Color('temp_distance_category:N',\n",
    "                    scale=alt.Scale(\n",
    "                        domain=list(color_scheme.keys()),\n",
    "                        range=list(color_scheme.values())\n",
    "            ),\n",
    "                             legend=alt.Legend(title=\"Temperature Range\") \n",
    "        )\n",
    "    ).properties(\n",
    "        title='Average Temperature Categories Relative to Optimal Temperature Range in 2023',\n",
    "        width=800,\n",
    "        height=500\n",
    "    ).project('albersUsa')  \n",
    "\n",
    "layered_map =  county_map_background + county_map_filled + state_map_background\n",
    "layered_map.show()\n",
    "file_name = '12_TEMP_CAT_MAP_2023'\n",
    "layered_map.save(f'{output_path}{file_name}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
